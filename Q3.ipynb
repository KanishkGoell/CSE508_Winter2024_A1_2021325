{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Lowercase, tokenize, remove stopwords and punctuation from text.\"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positional_index(directory):\n",
    "    positional_index = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        path = os.path.join(directory, filename)\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            tokens = preprocess_text(text)\n",
    "            for position, token in enumerate(tokens):\n",
    "                if token not in positional_index:\n",
    "                    positional_index[token] = {}\n",
    "                if filename not in positional_index[token]:\n",
    "                    positional_index[token][filename] = []\n",
    "                positional_index[token][filename].append(position)\n",
    "    return positional_index\n",
    "\n",
    "# Assuming 'preprocessed_files' is the directory with preprocessed files\n",
    "positional_index = create_positional_index('preprocessed_files')\n",
    "\n",
    "# Save the positional index\n",
    "with open('positional_index.pkl', 'wb') as f:\n",
    "    pickle.dump(positional_index, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('positional_index.pkl', 'rb') as f:\n",
    "    loaded_positional_index = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phrase_query(query, positional_index):\n",
    "    words = preprocess_text(query)\n",
    "    if len(words) > 5:\n",
    "        return \"Query length exceeds limit of 5 words\", []\n",
    "\n",
    "    valid_docs = set()\n",
    "    for word in words:\n",
    "        if word in positional_index:\n",
    "            if not valid_docs:\n",
    "                valid_docs = set(positional_index[word].keys())\n",
    "            else:\n",
    "                valid_docs &= set(positional_index[word].keys())\n",
    "        else:\n",
    "            return 0, []\n",
    "\n",
    "    # Filter documents by positional criteria\n",
    "    filtered_docs = []\n",
    "    for doc in valid_docs:\n",
    "        positions = [positional_index[word][doc] for word in words if doc in positional_index[word]]\n",
    "        for start_pos in positions[0]:\n",
    "            if all((start_pos + i in pos_list) for i, pos_list in enumerate(positions[1:], start=1)):\n",
    "                filtered_docs.append(doc)\n",
    "                break\n",
    "\n",
    "    return len(filtered_docs), filtered_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents retrieved for query 1 using positional index: 2\n",
      "Names of documents retrieved for query 1 using positional index: preprocessed_file484.txt, preprocessed_file277.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = int(input(\"Enter the number of queries: \"))\n",
    "for i in range(N):\n",
    "    query = input(f\"Enter query {i+1}: \")\n",
    "    num_docs, docs = process_phrase_query(query, loaded_positional_index)\n",
    "    print(f\"Number of documents retrieved for query {i+1} using positional index: {num_docs}\")\n",
    "    if num_docs > 0:\n",
    "        print(f\"Names of documents retrieved for query {i+1} using positional index: {', '.join(docs)}\")\n",
    "    else:\n",
    "        print(\"No documents retrieved for this query using positional index.\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
